{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "17753a94-c2c4-4751-a4e2-b963357f3370",
   "metadata": {},
   "source": [
    "## **Entrega Final: Automatización de un Pipeline de Machine Learning con GitHub Actions**  \n",
    "### Johanna Peña"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cdd22b85-453d-47cb-a17a-df7557b248a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'uci_id': 53, 'name': 'Iris', 'repository_url': 'https://archive.ics.uci.edu/dataset/53/iris', 'data_url': 'https://archive.ics.uci.edu/static/public/53/data.csv', 'abstract': 'A small classic dataset from Fisher, 1936. One of the earliest known datasets used for evaluating classification methods.\\n', 'area': 'Biology', 'tasks': ['Classification'], 'characteristics': ['Tabular'], 'num_instances': 150, 'num_features': 4, 'feature_types': ['Real'], 'demographics': [], 'target_col': ['class'], 'index_col': None, 'has_missing_values': 'no', 'missing_values_symbol': None, 'year_of_dataset_creation': 1936, 'last_updated': 'Tue Sep 12 2023', 'dataset_doi': '10.24432/C56C76', 'creators': ['R. A. Fisher'], 'intro_paper': {'ID': 191, 'type': 'NATIVE', 'title': 'The Iris data set: In search of the source of virginica', 'authors': 'A. Unwin, K. Kleinman', 'venue': 'Significance, 2021', 'year': 2021, 'journal': 'Significance, 2021', 'DOI': '1740-9713.01589', 'URL': 'https://www.semanticscholar.org/paper/4599862ea877863669a6a8e63a3c707a787d5d7e', 'sha': None, 'corpus': None, 'arxiv': None, 'mag': None, 'acl': None, 'pmid': None, 'pmcid': None}, 'additional_info': {'summary': 'This is one of the earliest datasets used in the literature on classification methods and widely used in statistics and machine learning.  The data set contains 3 classes of 50 instances each, where each class refers to a type of iris plant.  One class is linearly separable from the other 2; the latter are not linearly separable from each other.\\n\\nPredicted attribute: class of iris plant.\\n\\nThis is an exceedingly simple domain.\\n\\nThis data differs from the data presented in Fishers article (identified by Steve Chadwick,  spchadwick@espeedaz.net ).  The 35th sample should be: 4.9,3.1,1.5,0.2,\"Iris-setosa\" where the error is in the fourth feature. The 38th sample: 4.9,3.6,1.4,0.1,\"Iris-setosa\" where the errors are in the second and third features.  ', 'purpose': 'N/A', 'funded_by': None, 'instances_represent': 'Each instance is a plant', 'recommended_data_splits': None, 'sensitive_data': None, 'preprocessing_description': None, 'variable_info': None, 'citation': None}}\n",
      "           name     role         type demographic  \\\n",
      "0  sepal length  Feature   Continuous        None   \n",
      "1   sepal width  Feature   Continuous        None   \n",
      "2  petal length  Feature   Continuous        None   \n",
      "3   petal width  Feature   Continuous        None   \n",
      "4         class   Target  Categorical        None   \n",
      "\n",
      "                                         description units missing_values  \n",
      "0                                               None    cm             no  \n",
      "1                                               None    cm             no  \n",
      "2                                               None    cm             no  \n",
      "3                                               None    cm             no  \n",
      "4  class of iris plant: Iris Setosa, Iris Versico...  None             no  \n"
     ]
    }
   ],
   "source": [
    "#Cargue de datos\n",
    "from ucimlrepo import fetch_ucirepo \n",
    "  \n",
    "# fetch dataset \n",
    "iris = fetch_ucirepo(id=53) \n",
    "  \n",
    "# data (as pandas dataframes) \n",
    "X = iris.data.features \n",
    "y = iris.data.targets   \n",
    "# metadata \n",
    "print(iris.metadata) \n",
    "  \n",
    "# variable information \n",
    "print(iris.variables) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "42479ee6-5259-41ae-9495-9b5376f23d75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valores nulos por columna:\n",
      "sepal length    0\n",
      "sepal width     0\n",
      "petal length    0\n",
      "petal width     0\n",
      "dtype: int64\n",
      "\n",
      "Número de duplicados: 3\n"
     ]
    }
   ],
   "source": [
    "# Preprocesamiento y Entrenamiento del Modelo\n",
    "# Importar bibliotecas\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "import mlflow\n",
    "import mlflow.sklearn\n",
    "\n",
    "# Convertir los datos en un DataFrame para inspección\n",
    "df = pd.DataFrame(X, columns=iris.feature_names)\n",
    "\n",
    "# Revisión de valores nulos\n",
    "print(\"Valores nulos por columna:\")\n",
    "print(df.isnull().sum())\n",
    "\n",
    "# Revisar duplicados\n",
    "print(\"\\nNúmero de duplicados:\", df.duplicated().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a53ebc6a-123e-4011-b8b4-51dff65224a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Número de duplicados: 0\n"
     ]
    }
   ],
   "source": [
    "# Eliminar duplicados\n",
    "df = df.drop_duplicates()\n",
    "# Revisar duplicados\n",
    "print(\"\\nNúmero de duplicados:\", df.duplicated().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d6394217-c59a-409a-ae16-32ade54d44e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Distribución de las clases (target):\n",
      "Iris-setosa        50\n",
      "Iris-versicolor    50\n",
      "Iris-virginica     50\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Accuracy: 1.0\n",
      "\n",
      "Reporte de clasificación:\n",
      "                 precision    recall  f1-score   support\n",
      "\n",
      "    Iris-setosa       1.00      1.00      1.00        10\n",
      "Iris-versicolor       1.00      1.00      1.00         9\n",
      " Iris-virginica       1.00      1.00      1.00        11\n",
      "\n",
      "       accuracy                           1.00        30\n",
      "      macro avg       1.00      1.00      1.00        30\n",
      "   weighted avg       1.00      1.00      1.00        30\n",
      "\n",
      "\n",
      "Matriz de Confusión:\n",
      "[[10  0  0]\n",
      " [ 0  9  0]\n",
      " [ 0  0 11]]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "566fc62fe7ca42029d40a8dc042f8fb4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading artifacts:   0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Revisar distribución de las clases\n",
    "# Asegurarse de que y sea un vector unidimensional\n",
    "y = y.values.ravel()  # Convierte a unidimensional si no lo es\n",
    "\n",
    "# Ahora podemos usar pd.Series para verificar la distribución de las clases\n",
    "print(\"\\nDistribución de las clases (target):\")\n",
    "print(pd.Series(y).value_counts())\n",
    "\n",
    "# Dividir los datos en entrenamiento y prueba\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Escalar los datos\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Asegurarse de que y esté en la forma correcta (unidimensional)\n",
    "y_train = y_train.ravel()  # Aplana el array a una dimensión\n",
    "y_test = y_test.ravel()\n",
    "\n",
    "# Entrenar el modelo\n",
    "model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "model.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Hacer predicciones y evaluar\n",
    "y_pred = model.predict(X_test_scaled)\n",
    "\n",
    "# Evaluación del modelo\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"\\nAccuracy: {accuracy}\")\n",
    "\n",
    "# Imprimir reporte de clasificación (precisión, recall, F1-score)\n",
    "print(\"\\nReporte de clasificación:\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# Imprimir matriz de confusión\n",
    "print(\"\\nMatriz de Confusión:\")\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "\n",
    "# Iniciar el seguimiento con MLflow\n",
    "mlflow.set_tracking_uri(\"file:./mlruns\")\n",
    "mlflow.start_run()\n",
    "\n",
    "# Registrar parámetros del modelo\n",
    "mlflow.log_param(\"n_estimators\", 100)\n",
    "\n",
    "# Registrar métricas del modelo\n",
    "mlflow.log_metric(\"accuracy\", accuracy)\n",
    "\n",
    "# Registrar reporte de clasificación como texto\n",
    "mlflow.log_text(str(classification_report(y_test, y_pred)), \"classification_report.txt\")\n",
    "\n",
    "# Crear un ejemplo de entrada\n",
    "input_example = X_test_scaled[0].reshape(1, -1)\n",
    "\n",
    "# Registrar el modelo con ejemplo de entrada\n",
    "mlflow.sklearn.log_model(model, \"model\", input_example=input_example)\n",
    "\n",
    "# Finalizar el seguimiento\n",
    "mlflow.end_run()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
